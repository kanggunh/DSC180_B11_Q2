{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing CSV file to feed into Chatextract\n",
    "\n",
    "The csv file needs 3 column: \n",
    "- passage: Title, previous sentene, sentence we want to analyze\n",
    "- sentence: Sentence we want to anaylize\n",
    "- DOI\n",
    "\n",
    "\n",
    "Note: We will parse the XMl extracting certain informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import requests\n",
    "from urllib.parse import urlparse, urlunparse\n",
    "from io import BytesIO\n",
    "import pymupdf\n",
    "import os\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import tempfile\n",
    "import time\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "import grobid_tei_xml\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We will gather separate pdf for each downloadable link in paper 149 and parse them into xml separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_papers = pd.read_csv(\"../data/good_paper_links.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_dir = tempfile.mkdtemp()\n",
    "chrome_options = uc.ChromeOptions()\n",
    "chrome_options.add_experimental_option(\"prefs\", {\n",
    "    \"download.default_directory\": download_dir,  # Set download location\n",
    "    \"download.prompt_for_download\": False,       # Disable download prompts\n",
    "    \"plugins.always_open_pdf_externally\": True   # Download PDFs instead of opening them\n",
    "})\n",
    "driver = uc.Chrome(options=chrome_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_url(url):\n",
    "    parsed_url = urlparse(url)\n",
    "    # Reconstruct URL without query parameters and fragment\n",
    "    return urlunparse((parsed_url.scheme, parsed_url.netloc, parsed_url.path, '', '', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_pdf_if_button(driver):\n",
    "    try:\n",
    "        driver.find_element(By.XPATH, \"//embed[contains(@type, 'application/pdf')]\")\n",
    "        return True\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        for iframe in driver.find_elements(By.TAG_NAME, \"iframe\"):\n",
    "            try:\n",
    "                frame_type = iframe.get_attribute(\"type\")\n",
    "                if frame_type == \"application/pdf\":\n",
    "                    driver.get(iframe.get_attribute(\"src\"))\n",
    "                    return True\n",
    "            except:\n",
    "                print(f\"Failed to get link {iframe}\")\n",
    "                return False\n",
    "    except:\n",
    "        print(\"No open button found for current PDF\")\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_pdf_urls(url, paper_index):\n",
    "\n",
    "    driver.get(url)\n",
    "\n",
    "    pdfs_unique = set()\n",
    "    pdf_links = []\n",
    "    pdf_pattern = re.compile(r'(?<!e)\\.pdf$|/pdf/|/articlepdf/|/article-pdf/', re.IGNORECASE)\n",
    "    for link in driver.find_elements(By.TAG_NAME, \"a\"):\n",
    "        try:\n",
    "            href = link.get_attribute(\"href\")\n",
    "            if href and \"scholar.google\" not in href and pdf_pattern.search(href): #selenium cannot download epdfs\n",
    "                base_url = get_base_url(href)\n",
    "                if base_url not in pdfs_unique:\n",
    "                    pdfs_unique.add(base_url)\n",
    "                    pdf_links.append(href)\n",
    "        except:\n",
    "            print(f\"Failed to get link {link}\")\n",
    "            return\n",
    "    merged_pdf = pymupdf.open()\n",
    "    i = 0\n",
    "    if len(pdf_links) == 0:\n",
    "        print(f\"No PDF links found for paper {url}\")\n",
    "        return\n",
    "    downloadable_links_count = 0\n",
    "    for pdf_link in pdf_links:\n",
    "        # Ensure each link is a full URL\n",
    "        pdf_url = pdf_link if pdf_link.startswith('http') else get_base_url(url) + pdf_link\n",
    "        if \"pdf\" not in pdf_url: #skips non-pdfs after base url is used\n",
    "            continue\n",
    "        try:\n",
    "            num_of_files_prev = len([f for f in os.listdir(download_dir)])\n",
    "            curr_url = driver.current_url\n",
    "            driver.get(pdf_url)\n",
    "            if curr_url != driver.current_url: # redirected to another page\n",
    "                open_pdf_if_button(driver)\n",
    "            time.sleep(1)\n",
    "            num_of_files_now = len([f for f in os.listdir(download_dir)])\n",
    "            downloadable_links_count += num_of_files_now > num_of_files_prev\n",
    "        except:\n",
    "            print(f\"Skipping invalid PDF at {pdf_url}\")\n",
    "            continue\n",
    "    downloaded_pdfs = [f for f in os.listdir(download_dir) if f.endswith('.pdf')]\n",
    "    print(downloaded_pdfs)\n",
    "    while len(downloaded_pdfs) < downloadable_links_count:\n",
    "        time.sleep(1)\n",
    "        downloaded_pdfs = [f for f in os.listdir(download_dir) if f.endswith('.pdf')]\n",
    "        \n",
    "    pdf_files = [os.path.join(download_dir, f) for f in os.listdir(download_dir) if f.endswith('.pdf')]\n",
    "    count = 0\n",
    "    for pdf in pdf_files:\n",
    "        print(pdf)\n",
    "        output_path = f'{paper_index}-{count}.pdf'\n",
    "        merged_pdf.insert_pdf(pymupdf.open(pdf))\n",
    "        merged_pdf.save(output_path)\n",
    "        merged_pdf.close()\n",
    "        count += 1\n",
    "        merged_pdf = pymupdf.open()\n",
    "    \n",
    "    for pdf in pdf_files:\n",
    "        os.remove(pdf)\n",
    "    # print(f\"Merged PDF saved as {output_path}\")\n",
    "    return pdf_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['41586_2021_4372_MOESM1_ESM.pdf', 's41586-021-04372-8.pdf']\n",
      "C:\\Users\\Luna\\AppData\\Local\\Temp\\tmpud7gsy94\\41586_2021_4372_MOESM1_ESM.pdf\n",
      "C:\\Users\\Luna\\AppData\\Local\\Temp\\tmpud7gsy94\\s41586-021-04372-8.pdf\n"
     ]
    }
   ],
   "source": [
    "for index, row in good_papers.iterrows():\n",
    "    if index == 149:\n",
    "        download_pdf_urls(row['Link'], index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert these PDF into XML using Grobid\n",
    "\n",
    "1) Run Docker container\n",
    "2) Go to Grobid documentation and copy the terminal command to paste on your machine\n",
    "3) run the below code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "grobid_url = \"http://localhost:8070/api/processFulltextDocument\"\n",
    "xml_names = os.listdir(\"data/xmls\")\n",
    "\n",
    "for pdf_file in os.listdir(\"data/pdfs\"):\n",
    "    #only looks at pdf files\n",
    "    if pdf_file.endswith(\".pdf\"):\n",
    "        pdf_path = os.path.join(\"data/pdfs\", pdf_file)\n",
    "        #doe not convert already converted files\n",
    "        if pdf_path.replace('.pdf', '.xml') in xml_names:\n",
    "            continue\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            #GROBID must be running on port 8070 for this to work\n",
    "            response = requests.post(\n",
    "                grobid_url,\n",
    "                files={'input': file},\n",
    "                headers={'Accept': 'application/xml'}\n",
    "            )\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                xml_file_path = os.path.join('data/xmls', pdf_file.replace('.pdf', '.xml'))\n",
    "                with open(xml_file_path, 'w', encoding='utf-8') as xml_file:\n",
    "                    xml_file.write(response.text)\n",
    "            else:\n",
    "                print(f\"Failed to convert {pdf_file}. Status code: {response.status_code}\")\n",
    "                print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert XML into text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "##directory to xml file\n",
    "filename_sup = \"149-0.xml\"\n",
    "filename_article = \"149-1.xml\"\n",
    "filenames = [filename_sup, filename_article]\n",
    "\n",
    "DOI_149 = \"https://doi.org/10.1038/s41586-021-04372-8\"\n",
    "##This is manually looked into, for feeding chatextract to multiple paper, we need ways to aquire its correspondig link\n",
    "#Link available in this csv file \n",
    "good_papers = pd.read_csv(\"../data/good_paper_links.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xml_to_text(file_path):\n",
    "    tree = ET.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "    print(file_path)\n",
    "    print(root.find(\".//title\"))\n",
    "    title = \"\"\n",
    "    sections = []\n",
    "    figures = []\n",
    "    \n",
    "    namespace = { 'd': root.tag.split('}')[0].strip('{') if '}' in root.tag else '' }\n",
    "    def ns_tag(tag):\n",
    "        return f\"{{{namespace}}}tag\" if namespace else tag\n",
    "\n",
    "    print(namespace)\n",
    "    namespace = { 'd': \"http://www.tei-c.org/ns/1.0\" }\n",
    "    title_element = root.find('d:title', namespace)\n",
    "    if title_element is not None:\n",
    "        title = title_element.text\n",
    "    \n",
    "    for div in root.findall(\".//div\"):\n",
    "        section_text = \"/n\".join(div.itertext())\n",
    "        sections.append(section_text)\n",
    "    \n",
    "    for figure in root.findall(\".//figure\"):\n",
    "        fig_head = figure.find(\".//head\")\n",
    "        fig_description = figure.find(\".//figDesc\")\n",
    "        fig_info = (fig_head.text if fig_head else \"Fig:\") + \" \" \n",
    "        + (fig_description.text if fig_description else \"unkown description\")\n",
    "        figures.append(fig_info)\n",
    "    return title + \"/n\" + \"/n\".join(sections) + \"/n\" + \"/n\".join(figures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_grobid_xml(file_path):\n",
    "    with open(file_path, \"r\") as xml_file:\n",
    "        doc = grobid_tei_xml.parse_document_xml(xml_file.read())\n",
    "        title = doc.header.title or \"\"\n",
    "        abstract = doc.abstract or \"\"\n",
    "        body = doc.body or \"\"\n",
    "        index = file_path.split(\"/\")[-1].split(\".\")[0]\n",
    "        return f\"Paper #: {index}\\ntitle:{title}\\nAbstract:\\n{abstract}\\nBody:\\n{body}\" #title, abstract, body\n",
    "    # print(json.dumps(doc.to_dict(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149-0.xml\n",
      "149-1.xml\n"
     ]
    }
   ],
   "source": [
    "xml_dir = \"data/xmls\"\n",
    "txt_dir = \"data/txts\"\n",
    "for filename in os.listdir(\"data/xmls\"):\n",
    "    if filename.endswith(\".xml\"):\n",
    "        print(filename)\n",
    "        txt_content = parse_grobid_xml(os.path.join(xml_dir, filename))\n",
    "        txt_file = os.path.join(txt_dir, f\"{os.path.splitext(filename)[0]}.txt\")\n",
    "        with open(txt_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(txt_content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create rc_data.csv where sentence is a paragraph\n",
    "\n",
    "Idea: Each line on the txt is its own paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_149_article = 'data/txts\\\\149-1.txt'\n",
    "txt_149_sup = 'data/txts\\\\149-0.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Identifying the title and paragraph from txt\n",
    "paragraph_list = []\n",
    "\n",
    "with open(txt_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    txt_list = f.readlines()\n",
    "for line in txt_list:\n",
    "    # print(line)\n",
    "    if line.startswith(\"title:\"):\n",
    "        title = line[6:]\n",
    "        continue\n",
    "    if line.startswith(\"Paper #\") | line.startswith(\"Abstract:\") | line.startswith(\"Body:\"):\n",
    "        continue\n",
    "    else:\n",
    "        paragraph_list.append(line)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>DOI</th>\n",
       "      <th>shift</th>\n",
       "      <th>passage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All-perovskite tandem solar cells hold the pro...</td>\n",
       "      <td>https://doi.org/10.1038/s41586-021-04372-8</td>\n",
       "      <td></td>\n",
       "      <td>All-perovskite tandem solar cells with improve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Metal-halide perovskites are emerging photovol...</td>\n",
       "      <td>https://doi.org/10.1038/s41586-021-04372-8</td>\n",
       "      <td>All-perovskite tandem solar cells hold the pro...</td>\n",
       "      <td>All-perovskite tandem solar cells with improve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Density functional theory studies Here we inv...</td>\n",
       "      <td>https://doi.org/10.1038/s41586-021-04372-8</td>\n",
       "      <td>Metal-halide perovskites are emerging photovol...</td>\n",
       "      <td>All-perovskite tandem solar cells with improve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PV performance of Pb-Sn PSCs DFT calculations...</td>\n",
       "      <td>https://doi.org/10.1038/s41586-021-04372-8</td>\n",
       "      <td>Density functional theory studies Here we inv...</td>\n",
       "      <td>All-perovskite tandem solar cells with improve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Characterization of Pb-Sn perovskites To unde...</td>\n",
       "      <td>https://doi.org/10.1038/s41586-021-04372-8</td>\n",
       "      <td>PV performance of Pb-Sn PSCs DFT calculations...</td>\n",
       "      <td>All-perovskite tandem solar cells with improve...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  All-perovskite tandem solar cells hold the pro...   \n",
       "1  Metal-halide perovskites are emerging photovol...   \n",
       "2   Density functional theory studies Here we inv...   \n",
       "3   PV performance of Pb-Sn PSCs DFT calculations...   \n",
       "4   Characterization of Pb-Sn perovskites To unde...   \n",
       "\n",
       "                                          DOI  \\\n",
       "0  https://doi.org/10.1038/s41586-021-04372-8   \n",
       "1  https://doi.org/10.1038/s41586-021-04372-8   \n",
       "2  https://doi.org/10.1038/s41586-021-04372-8   \n",
       "3  https://doi.org/10.1038/s41586-021-04372-8   \n",
       "4  https://doi.org/10.1038/s41586-021-04372-8   \n",
       "\n",
       "                                               shift  \\\n",
       "0                                                      \n",
       "1  All-perovskite tandem solar cells hold the pro...   \n",
       "2  Metal-halide perovskites are emerging photovol...   \n",
       "3   Density functional theory studies Here we inv...   \n",
       "4   PV performance of Pb-Sn PSCs DFT calculations...   \n",
       "\n",
       "                                             passage  \n",
       "0  All-perovskite tandem solar cells with improve...  \n",
       "1  All-perovskite tandem solar cells with improve...  \n",
       "2  All-perovskite tandem solar cells with improve...  \n",
       "3  All-perovskite tandem solar cells with improve...  \n",
       "4  All-perovskite tandem solar cells with improve...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Creating a pandas df\n",
    "\n",
    "# Create the DataFrame\n",
    "article_149= pd.DataFrame({\n",
    "    \"sentence\": paragraph_list,\n",
    "    \"DOI\": DOI_149  # This assigns the same DOI to every row\n",
    "})\n",
    "article_149[\"shift\"] = article_149[\"sentence\"].shift(1).fillna('')\n",
    "article_149[\"passage\"] = title+ article_149[\"shift\"] +article_149[\"sentence\"]\n",
    "article_149.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                      \n",
       "1     All-perovskite tandem solar cells hold the pro...\n",
       "2     Metal-halide perovskites are emerging photovol...\n",
       "3      Density functional theory studies Here we inv...\n",
       "4      PV performance of Pb-Sn PSCs DFT calculations...\n",
       "5      Characterization of Pb-Sn perovskites To unde...\n",
       "6      Performance and stability of tandem solar cel...\n",
       "7      Article The best tandem cell had a PCE of 26....\n",
       "8      Online content Any methods, additional refere...\n",
       "9                                            Methods \\n\n",
       "10     DFT simulation Ab initio molecular dynamic si...\n",
       "11     Materials All materials were used as received...\n",
       "12     Perovskite precursor solution NBG FA 0.7 MA 0...\n",
       "13     Device fabrication Mixed Pb-Sn perovskite sol...\n",
       "14     Characterization of solar cells For single-ju...\n",
       "15     Stability tests of solar cells The operating ...\n",
       "16     Femtosecond-resolved optical-pump-terahertz p...\n",
       "17     Optical simulation of tandem solar cells A va...\n",
       "18     2 1Fig. 2 | 22 Fig. 2 | PV performance of Pb-...\n",
       "19     Fig. 3 | 3 Fig. 3 | Characterization of mixed...\n",
       "20     2 )Fig. 4 | 24 Fig. 4 | PV performance and st...\n",
       "21     Extended Data Fig. 1 | 1 Optical simulation o...\n",
       "22                                                   \\n\n",
       "23                                                   \\n\n",
       "24                                                   \\n\n",
       "25                                                   \\n\n",
       "26                                                   \\n\n",
       "27                                                   \\n\n",
       "28                                                   \\n\n",
       "29                                                   \\n\n",
       "Name: sentence, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_149[\"sentence\"].shift(1).fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
