{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import urllib\n",
    "from urllib.parse import urlparse, urlunparse\n",
    "from io import BytesIO\n",
    "import os\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import tempfile\n",
    "import time\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_dir = tempfile.mkdtemp() # os.getcwd() + '/data/pdfs'\n",
    "chrome_options = uc.ChromeOptions()\n",
    "chrome_options.add_experimental_option(\"prefs\", {\n",
    "    \"download.default_directory\": download_dir,  # Set download location\n",
    "    \"download.prompt_for_download\": False,       # Disable download prompts\n",
    "    \"plugins.always_open_pdf_externally\": True   # Download PDFs instead of opening them\n",
    "})\n",
    "service = Service(ChromeDriverManager().install())\n",
    "driver = uc.Chrome(service=service, options=chrome_options)\n",
    "driver.implicitly_wait(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_url(url):\n",
    "    parsed_url = urlparse(url)\n",
    "    # Reconstruct URL without query parameters and fragment\n",
    "    return urlunparse((parsed_url.scheme, parsed_url.netloc, parsed_url.path, '', '', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_pdf_if_button(driver):\n",
    "    try:\n",
    "        driver.find_element(By.XPATH, \"//embed[contains(@type, 'application/pdf')]\")\n",
    "        return True\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        for iframe in driver.find_elements(By.TAG_NAME, \"iframe\"):\n",
    "            try:\n",
    "                frame_type = iframe.get_attribute(\"type\")\n",
    "                if frame_type == \"application/pdf\":\n",
    "                    driver.get(iframe.get_attribute(\"src\"))\n",
    "                    return True\n",
    "            except:\n",
    "                print(f\"Failed to get link {iframe}\")\n",
    "                return False\n",
    "    except:\n",
    "        print(\"No open button found for current PDF\")\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_pdf_urls(url, paper_index):\n",
    "\n",
    "    driver.get(url)\n",
    "    try:\n",
    "    # Wait for up to 5 seconds for the button to appear and be clickable\n",
    "        cookie_button = WebDriverWait(driver, 3).until(\n",
    "        EC.element_to_be_clickable((By.XPATH, \"//*[contains(text(), 'Accept all cookies')]\"))\n",
    "    )\n",
    "        cookie_button.click()\n",
    "        print(\"Accepted cookies.\")\n",
    "    except:\n",
    "        print(\"No 'Accept all cookies' button found or it is not clickable.\")\n",
    "\n",
    "\n",
    "    pdfs_unique = set()\n",
    "    pdf_links = []\n",
    "    pdf_pattern = re.compile(r'(?<!e)\\.pdf$|/pdf/|/articlepdf/|/article-pdf/', re.IGNORECASE)\n",
    "    for link in driver.find_elements(By.TAG_NAME, \"a\"):\n",
    "        try:\n",
    "            href = link.get_attribute(\"href\")\n",
    "            try:\n",
    "                link.find_element(By.XPATH, \"./ancestor::div[@id='recommended-articles']\")\n",
    "                continue #skips if link is in recommended\n",
    "            except NoSuchElementException:\n",
    "                try:    \n",
    "                    link.find_element(By.XPATH, \"./ancestor::ol[@class='references']\")\n",
    "                    continue #skips if link is in references\n",
    "                except:\n",
    "                    if href and \"scholar.google\" not in href and pdf_pattern.search(href): #selenium cannot download epdfs\n",
    "                        base_url = get_base_url(href)\n",
    "                        if base_url not in pdfs_unique:\n",
    "                            pdfs_unique.add(base_url)\n",
    "                            pdf_links.append(href)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            break\n",
    "            print(f\"Failed to get link {link}\")\n",
    "    i = 0\n",
    "    if len(pdf_links) == 0:\n",
    "        print(f\"No PDF links found for paper {url}\")\n",
    "        return\n",
    "    downloadable_links_count = 0\n",
    "    for pdf_link in pdf_links:\n",
    "        # Ensure each link is a full URL\n",
    "        pdf_url = pdf_link if pdf_link.startswith('http') else get_base_url(url) + pdf_link\n",
    "        if \"pdf\" not in pdf_url: #skips non-pdfs after base url is used\n",
    "            continue\n",
    "        try:\n",
    "            num_of_files_prev = len([f for f in os.listdir(download_dir)])\n",
    "            curr_url = driver.current_url\n",
    "            driver.get(pdf_url)\n",
    "            if curr_url != driver.current_url: # redirected to another page\n",
    "                open_pdf_if_button(driver)\n",
    "            time.sleep(1)\n",
    "            num_of_files_now = len([f for f in os.listdir(download_dir)])\n",
    "            downloadable_links_count += num_of_files_now > num_of_files_prev\n",
    "            # if downloaded:\n",
    "            #     time.sleep(1)\n",
    "            #     os.chdir(download_dir)\n",
    "            #     files = filter(os.path.isfile , os.listdir(download_dir)) \n",
    "            #     files = [os.path.join(download_dir, f) for f in files]\n",
    "            #     files.sort(key=lambda x: os.path.getmtime(x))\n",
    "            #     newest_file = files[-1]\n",
    "            #     os.rename(newest_file, f\"{paper_index}_{i}.pdf\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(f\"Skipping invalid PDF at {pdf_url}\")\n",
    "            continue\n",
    "    downloaded_pdfs = [f for f in os.listdir(download_dir) if f.endswith('.pdf')]\n",
    "    while len(downloaded_pdfs) < downloadable_links_count:\n",
    "        time.sleep(1)\n",
    "        downloaded_pdfs = [f for f in os.listdir(download_dir) if f.endswith('.pdf')]\n",
    "    print(f\"Downloaded {len(downloaded_pdfs)} PDFs for {url}\")\n",
    "    pdf_files = [os.path.join(download_dir, f) for f in os.listdir(download_dir) if f.endswith('.pdf')]\n",
    "    i = 1\n",
    "    for pdf in pdf_files:\n",
    "        output_path = os.path.abspath(os.getcwd() +f'/data/pdfs/{paper_index}_{i}.pdf')\n",
    "        os.rename(pdf, output_path)\n",
    "        i += 1 \n",
    "\n",
    "        \n",
    "    # for pdf in pdf_files:\n",
    "    #     if os.path.exists(pdf):\n",
    "    #         os.remove(pdf)\n",
    "    return len(pdf_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('../data/crossref_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOI</th>\n",
       "      <th>URL</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10.1016/j.matlet.2024.137407</td>\n",
       "      <td>https://doi.org/10.1016/j.matlet.2024.137407</td>\n",
       "      <td>2024</td>\n",
       "      <td>['Defect passivation of organometal halide per...</td>\n",
       "      <td>Elsevier BV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>10.1016/j.cej.2024.152955</td>\n",
       "      <td>https://doi.org/10.1016/j.cej.2024.152955</td>\n",
       "      <td>2024</td>\n",
       "      <td>['4-Methoxy phenethylammonium halide salts for...</td>\n",
       "      <td>Elsevier BV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>10.1016/j.solmat.2023.112630</td>\n",
       "      <td>https://doi.org/10.1016/j.solmat.2023.112630</td>\n",
       "      <td>2023</td>\n",
       "      <td>['Surface defect passivation by copper incorpo...</td>\n",
       "      <td>Elsevier BV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>10.1016/j.solener.2024.112968</td>\n",
       "      <td>https://doi.org/10.1016/j.solener.2024.112968</td>\n",
       "      <td>2024</td>\n",
       "      <td>['Defects passivation in chloride-iodide perov...</td>\n",
       "      <td>Elsevier BV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>10.1016/j.cej.2024.150903</td>\n",
       "      <td>https://doi.org/10.1016/j.cej.2024.150903</td>\n",
       "      <td>2024</td>\n",
       "      <td>['In-Situ passivation of mixed-halide perovski...</td>\n",
       "      <td>Elsevier BV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49943</th>\n",
       "      <td>10.1016/j.jobe.2019.101080</td>\n",
       "      <td>https://doi.org/10.1016/j.jobe.2019.101080</td>\n",
       "      <td>2019</td>\n",
       "      <td>['Multi-objective design of grid-tied solar ph...</td>\n",
       "      <td>Elsevier BV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49948</th>\n",
       "      <td>10.1016/j.solener.2020.04.040</td>\n",
       "      <td>https://doi.org/10.1016/j.solener.2020.04.040</td>\n",
       "      <td>2020</td>\n",
       "      <td>['Experimental investigation on the geometric ...</td>\n",
       "      <td>Elsevier BV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49949</th>\n",
       "      <td>10.1016/j.solener.2020.04.090</td>\n",
       "      <td>https://doi.org/10.1016/j.solener.2020.04.090</td>\n",
       "      <td>2020</td>\n",
       "      <td>['Thermal performance evaluation of a passive ...</td>\n",
       "      <td>Elsevier BV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49950</th>\n",
       "      <td>10.1016/j.jastp.2020.105472</td>\n",
       "      <td>https://doi.org/10.1016/j.jastp.2020.105472</td>\n",
       "      <td>2020</td>\n",
       "      <td>['Trends of thermodynamic indices thresholds o...</td>\n",
       "      <td>Elsevier BV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>10.1016/j.matlet.2020.128036</td>\n",
       "      <td>https://doi.org/10.1016/j.matlet.2020.128036</td>\n",
       "      <td>2020</td>\n",
       "      <td>['Synthesis of gallium arsenide nanostructures...</td>\n",
       "      <td>Elsevier BV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13012 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 DOI  \\\n",
       "16      10.1016/j.matlet.2024.137407   \n",
       "39         10.1016/j.cej.2024.152955   \n",
       "44      10.1016/j.solmat.2023.112630   \n",
       "46     10.1016/j.solener.2024.112968   \n",
       "47         10.1016/j.cej.2024.150903   \n",
       "...                              ...   \n",
       "49943     10.1016/j.jobe.2019.101080   \n",
       "49948  10.1016/j.solener.2020.04.040   \n",
       "49949  10.1016/j.solener.2020.04.090   \n",
       "49950    10.1016/j.jastp.2020.105472   \n",
       "49998   10.1016/j.matlet.2020.128036   \n",
       "\n",
       "                                                 URL  year  \\\n",
       "16      https://doi.org/10.1016/j.matlet.2024.137407  2024   \n",
       "39         https://doi.org/10.1016/j.cej.2024.152955  2024   \n",
       "44      https://doi.org/10.1016/j.solmat.2023.112630  2023   \n",
       "46     https://doi.org/10.1016/j.solener.2024.112968  2024   \n",
       "47         https://doi.org/10.1016/j.cej.2024.150903  2024   \n",
       "...                                              ...   ...   \n",
       "49943     https://doi.org/10.1016/j.jobe.2019.101080  2019   \n",
       "49948  https://doi.org/10.1016/j.solener.2020.04.040  2020   \n",
       "49949  https://doi.org/10.1016/j.solener.2020.04.090  2020   \n",
       "49950    https://doi.org/10.1016/j.jastp.2020.105472  2020   \n",
       "49998   https://doi.org/10.1016/j.matlet.2020.128036  2020   \n",
       "\n",
       "                                                   title    publisher  \n",
       "16     ['Defect passivation of organometal halide per...  Elsevier BV  \n",
       "39     ['4-Methoxy phenethylammonium halide salts for...  Elsevier BV  \n",
       "44     ['Surface defect passivation by copper incorpo...  Elsevier BV  \n",
       "46     ['Defects passivation in chloride-iodide perov...  Elsevier BV  \n",
       "47     ['In-Situ passivation of mixed-halide perovski...  Elsevier BV  \n",
       "...                                                  ...          ...  \n",
       "49943  ['Multi-objective design of grid-tied solar ph...  Elsevier BV  \n",
       "49948  ['Experimental investigation on the geometric ...  Elsevier BV  \n",
       "49949  ['Thermal performance evaluation of a passive ...  Elsevier BV  \n",
       "49950  ['Trends of thermodynamic indices thresholds o...  Elsevier BV  \n",
       "49998  ['Synthesis of gallium arsenide nanostructures...  Elsevier BV  \n",
       "\n",
       "[13012 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[dataset[\"URL\"].str.contains('\\/j\\.') & (dataset[\"publisher\"] == \"Elsevier BV\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30       https://doi.org/10.2139/ssrn.4918801\n",
       "33       https://doi.org/10.2139/ssrn.4803193\n",
       "53       https://doi.org/10.2139/ssrn.4972021\n",
       "55       https://doi.org/10.2139/ssrn.5070698\n",
       "60       https://doi.org/10.2139/ssrn.4932764\n",
       "                         ...                 \n",
       "49515    https://doi.org/10.2139/ssrn.3604729\n",
       "49546    https://doi.org/10.2139/ssrn.3603627\n",
       "49859    https://doi.org/10.2139/ssrn.3517092\n",
       "49880    https://doi.org/10.2139/ssrn.3735400\n",
       "49894    https://doi.org/10.2139/ssrn.3716945\n",
       "Name: URL, Length: 1794, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssrn = dataset[dataset[\"URL\"].str.contains(\"ssrn\")]\n",
    "ssrn[\"URL\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://doi.org/10.1016/j.matlet.2024.137407\n",
      "No 'Accept all cookies' button found or it is not clickable.\n",
      "Downloaded 1 PDFs for https://doi.org/10.1016/j.matlet.2024.137407\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/var/folders/8g/4zq2fslx2tv4wd4xlkpfgyb80000gn/T/tmp8lhpc3fb/1-s2.0-S0167577X24015477-main.pdf' -> '/Users/nic-macbook/repos/DSC180_B11_Q2/q2_submission_notebooks/data/pdfs/2000_1.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://doi.org/10.1016/j.matlet.2024.137407\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(url)\n\u001b[0;32m----> 7\u001b[0m num_links \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_pdf_urls\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_links \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      9\u001b[0m     failed_links\u001b[38;5;241m.\u001b[39mappend(row)\n",
      "Cell \u001b[0;32mIn[11], line 78\u001b[0m, in \u001b[0;36mdownload_pdf_urls\u001b[0;34m(url, paper_index)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pdf \u001b[38;5;129;01min\u001b[39;00m pdf_files:\n\u001b[1;32m     77\u001b[0m     output_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(os\u001b[38;5;241m.\u001b[39mgetcwd() \u001b[38;5;241m+\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/data/pdfs/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpaper_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pdf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 78\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m     i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# for pdf in pdf_files:\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m#     if os.path.exists(pdf):\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m#         os.remove(pdf)\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/var/folders/8g/4zq2fslx2tv4wd4xlkpfgyb80000gn/T/tmp8lhpc3fb/1-s2.0-S0167577X24015477-main.pdf' -> '/Users/nic-macbook/repos/DSC180_B11_Q2/q2_submission_notebooks/data/pdfs/2000_1.pdf'"
     ]
    }
   ],
   "source": [
    "i = 2000\n",
    "failed_links = []\n",
    "for index, row in dataset.iterrows():\n",
    "    url = row[\"URL\"]\n",
    "    url = \"https://doi.org/10.1016/j.matlet.2024.137407\"\n",
    "    print(url)\n",
    "    num_links = download_pdf_urls(url, i)\n",
    "    if num_links == 0:\n",
    "        failed_links.append(row)\n",
    "    i += 1\n",
    "    time.sleep(1)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicco\\source\\repos\\DSC180_B11_Q2\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert PDFs to XML using GROBID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grobid_url = \"http://localhost:8070/api/processFulltextDocument\"\n",
    "xml_names = os.listdir(\"../../data/xmls\")\n",
    "\n",
    "for pdf_file in os.listdir(\"../../data/pdfs\"):\n",
    "    \n",
    "    #only looks at pdf files\n",
    "    if pdf_file.endswith(\".pdf\"):\n",
    "        pdf_path = os.path.join(\"../../data/pdfs\", pdf_file)\n",
    "        #doe not convert already converted files\n",
    "        if pdf_path.replace('.pdf', '.xml') in xml_names:\n",
    "            continue\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            #GROBID must be running on port 8070 for this to work\n",
    "            response = requests.post(\n",
    "                grobid_url,\n",
    "                files={'input': file},\n",
    "                headers={'Accept': 'application/xml'}\n",
    "            )\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                xml_file_path = os.path.join('../../data/xmls', pdf_file.replace('.pdf', '.xml'))\n",
    "                with open(xml_file_path, 'w', encoding='utf-8') as xml_file:\n",
    "                    xml_file.write(response.text)\n",
    "            else:\n",
    "                print(f\"Failed to convert {pdf_file}. Status code: {response.status_code}\")\n",
    "                print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
